{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CGAN_inception.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0a8LRIuggnMa","executionInfo":{"status":"ok","timestamp":1639387812195,"user_tz":-540,"elapsed":1846,"user":{"displayName":"김하운","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13283057320954165001"}},"outputId":"9499c678-0a00-4855-a676-7e277c7d5c59"},"execution_count":136,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/CS_Vision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_-EurSZjgoTx","executionInfo":{"status":"ok","timestamp":1639387812196,"user_tz":-540,"elapsed":24,"user":{"displayName":"김하운","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13283057320954165001"}},"outputId":"99724709-2e37-44aa-d2d0-57928362ecc8"},"execution_count":137,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CS_Vision\n"]}]},{"cell_type":"code","source":["import torch, time, os, pickle\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","import os, gzip, torch\n","import scipy.misc\n","import imageio\n","import matplotlib.pyplot as plt\n","import imageio\n","from torch.nn import functional as F"],"metadata":{"id":"Rp7LQY0ag_SM","executionInfo":{"status":"ok","timestamp":1639387812197,"user_tz":-540,"elapsed":20,"user":{"displayName":"김하운","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13283057320954165001"}}},"execution_count":138,"outputs":[]},{"cell_type":"code","source":["class Generator(nn.Module):\n","    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n","    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n","    def __init__(self, input_dim=100, output_dim=1, input_size=32, class_num=10):\n","        super(Generator, self).__init__()\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","        self.input_size = input_size\n","        self.class_num = class_num\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(self.input_dim + self.class_num, 1024),\n","            nn.BatchNorm1d(1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 128 * (self.input_size // 4) * (self.input_size // 4)),\n","            nn.BatchNorm1d(128 * (self.input_size // 4) * (self.input_size // 4)),\n","            nn.ReLU(),\n","        )\n","        self.deconv = nn.Sequential(\n","            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n","            nn.Tanh(),\n","        )\n","        initialize_weights(self)\n","\n","    def forward(self, input, label):\n","        x = torch.cat([input, label], 1)\n","        x = self.fc(x)\n","        x = x.view(-1, 128, (self.input_size // 4), (self.input_size // 4))\n","        x = self.deconv(x)\n","\n","        return x"],"metadata":{"id":"bTGmfpgug7k8","executionInfo":{"status":"ok","timestamp":1639387812674,"user_tz":-540,"elapsed":496,"user":{"displayName":"김하운","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13283057320954165001"}}},"execution_count":139,"outputs":[]},{"cell_type":"code","source":["def initialize_weights(net):\n","    for m in net.modules():\n","        if isinstance(m, nn.Conv2d):\n","            m.weight.data.normal_(0, 0.02)\n","            m.bias.data.zero_()\n","        elif isinstance(m, nn.ConvTranspose2d):\n","            m.weight.data.normal_(0, 0.02)\n","            m.bias.data.zero_()\n","        elif isinstance(m, nn.Linear):\n","            m.weight.data.normal_(0, 0.02)\n","            m.bias.data.zero_()\n","\n","def save_images(images, size, image_path):\n","    return imsave(images, size, image_path)\n","\n","def imsave(images, size, path):\n","    image = np.squeeze(merge(images, size))\n","    # return scipy.misc.imsave(path, image)\n","    return imageio.imwrite(path, image)\n","\n","def merge(images, size):\n","    h, w = images.shape[1], images.shape[2]\n","    if (images.shape[3] in (3,4)):\n","        c = images.shape[3]\n","        img = np.zeros((h * size[0], w * size[1], c))\n","        for idx, image in enumerate(images):\n","            i = idx % size[1]\n","            j = idx // size[1]\n","            img[j * h:j * h + h, i * w:i * w + w, :] = image\n","        return img\n","    elif images.shape[3]==1:\n","        img = np.zeros((h * size[0], w * size[1]))\n","        for idx, image in enumerate(images):\n","            i = idx % size[1]\n","            j = idx // size[1]\n","            img[j * h:j * h + h, i * w:i * w + w] = image[:,:,0]\n","        return img\n","    else:\n","        raise ValueError('in merge(images,size) images parameter ''must have dimensions: HxW or HxWx3 or HxWx4')"],"metadata":{"id":"t3rrNbwRhMjz","executionInfo":{"status":"ok","timestamp":1639387812675,"user_tz":-540,"elapsed":6,"user":{"displayName":"김하운","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13283057320954165001"}}},"execution_count":140,"outputs":[]},{"cell_type":"code","execution_count":141,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HX-17La7gZqZ","executionInfo":{"status":"ok","timestamp":1639387813055,"user_tz":-540,"elapsed":385,"user":{"displayName":"김하운","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13283057320954165001"}},"outputId":"87949c6f-0d24-43b8-a116-571ac33bc694"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"]},{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'>\n","torch.Size([100, 10])\n","<class 'torch.Tensor'>\n","torch.Size([100, 1, 28, 28])\n"]}],"source":["## Generator 모델 가져오기\n","model = Generator(input_dim=100, output_dim=1, input_size=28, class_num=10)\n","optimizer = optim.Adam(model.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","\n","checkpoint = torch.load('./models/mnist/CGAN/CGAN_G.pkl')\n","model.load_state_dict(checkpoint)\n","\n","model.eval()\n","\n","batch_size =  100\n","class_num = 10 \n","z_dim = 100\n","\n","\n","sample_y_ = torch.zeros(batch_size, class_num).scatter_(1, torch.randint(0, class_num - 1, (batch_size, 1)).type(torch.LongTensor), 1)\n","sample_z_ = torch.rand((batch_size, z_dim))\n","# sample_z_, sample_y_ = sample_z_.cuda(), sample_y_.cuda()\n","print(type(sample_y_))\n","print(sample_y_.shape)\n","\n","\n","samples = model(sample_z_, sample_y_)\n","print(type(samples))\n","print(samples.shape)\n","samples = samples.data.numpy().transpose(0, 2, 3, 1)\n","# print(type(samples))\n","# print(samples.shape)\n","samples = (samples + 1) / 2 \n","save_images(samples[:10 * 10, :, :, :], [10, 10], './inception/img_cgan/test3.png')"]},{"cell_type":"code","source":["cd ./inception/"],"metadata":{"id":"s5vZtfLi_nPm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639387813056,"user_tz":-540,"elapsed":10,"user":{"displayName":"김하운","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13283057320954165001"}},"outputId":"c902c055-c8e4-4acf-83dd-2d597c1799ac"},"execution_count":142,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/CS_Vision/inception\n"]}]},{"cell_type":"code","source":["class BasicBlock(nn.Module):\n","    expansion = 1\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","def ResNet18():\n","    return ResNet(BasicBlock, [2,2,2,2])"],"metadata":{"id":"OGuoMmhrB35f","executionInfo":{"status":"ok","timestamp":1639387813057,"user_tz":-540,"elapsed":7,"user":{"displayName":"김하운","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13283057320954165001"}}},"execution_count":143,"outputs":[]},{"cell_type":"code","source":["import os,sys\n","import imageio\n","import numpy as np\n","import argparse\n","import math\n","import torchvision.transforms as transforms\n","import torch\n","import cv2 as cv\n","import glob as glob\n","from numpy import clip\n","\n","from skimage.transform import resize\n","from google.colab.patches import cv2_imshow\n","\n","in_path = \"./img_cgan/\"\n","out_path = in_path + \"crop_cgan/\"\n","input_image_dir = out_path\n","model_dir = \"./mnist_model_10.ckpt\"\n","img_size = 28\n","batch_size = 34\n","channel = 1\n","num_splits = 10\n","\n","GPUID = 0\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPUID)\n","print (\"PACKAGES LOADED\")\n","\n","def load_images(image_dir):\n","    images = []\n","    for fn in os.listdir(image_dir):\n","        ext = os.path.splitext(fn)[1].lower()\n","        img_path = os.path.join(image_dir, fn)\n","        img = imageio.imread(img_path)\n","        img = resize(img, (28, 28))\n","        # img = img[:, :, 0]\n","        # print(np.array(img).shape)\n","        # calculate per-channel means and standard deviations\n","        means = img.mean(axis=(0, 1), dtype='float64')\n","        stds = img.std(axis=(0, 1), dtype='float64')\n","        # per-channel standardization of pixels\n","        pixels = (img - means) / stds\n","        pixels = clip(pixels, -1.0, 1.0)\n","        images.append(pixels)\n","    # print(np.array(images).shape)\n","    return images\n","\n","\n","def softmax(x):\n","    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n","    e_x = np.exp(x - np.max(x))\n","    return e_x / np.expand_dims(e_x.sum(axis=1), axis=1)   # only difference\n","\n","\n","def preds2score(preds, splits=10):\n","    scores = []\n","    for i in range(splits):\n","        part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]\n","        kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n","        kl = np.mean(np.sum(kl, 1))\n","        scores.append(np.exp(kl))\n","    return np.mean(scores), np.std(scores)\n","\n","def get_inception_score(images):\n","    splits = num_splits\n","    inps = []\n","    input_transform = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    for img in images:\n","        img = img.astype(np.float32)\n","        inps.append(np.expand_dims(img, 0))\n","    preds = []\n","    n_batches = 2\n","    n_preds = 0\n","\n","    net = ResNet18()\n","    net.load_state_dict(torch.load(model_dir))\n","    print(\"load model successfully\")\n","    \n","    for i in range(n_batches):\n","        sys.stdout.write(\".\")\n","        sys.stdout.flush()\n","        inp = inps[(i * batch_size):min((i + 1) * batch_size, len(inps))]\n","        inp = np.concatenate(inp, 0)\n","        inp = np.expand_dims(inp, axis=1)\n","        # inp = torch.from_numpy(inp).cuda()\n","        inp = torch.from_numpy(inp)\n","        outputs = net(inp)\n","        pred = outputs.data.tolist()\n","        #pred = softmax(pred)\n","        preds.append(pred)\n","        n_preds += outputs.shape[0]\n","    preds = np.concatenate(preds, 0)\n","    preds = np.exp(preds) / np.sum(np.exp(preds), 1, keepdims=True)\n","    mean_, std_ = preds2score(preds, splits)\n","    return mean_, std_\n","\n","def crop10x10(in_path, out_path):\n","    # mnist\n","    x_cors = [0,28,56,84,112,140,168,196,224,252]\n","    y_cors = [0,28,56,84,112,140,168,196,224,252]\n","    img_size = 28\n","    number_channel = 1\n","\n","    print(out_path)\n","    if not os.path.exists(out_path):\n","        os.makedirs(out_path)\n","    in_list = glob.glob(in_path + \"*.png\")\n","    count = 0\n","    for img_name in in_list:\n","        count += 1\n","        if (number_channel == 1):\n","            img = cv.imread(img_name, 0)\n","        else:\n","            img = cv.imread(img_name, 1)\n","        for x in x_cors:\n","            for y in y_cors:\n","                img_crop = img[x:x + img_size, y:y + img_size]\n","                # print(img_crop.shape)\n","                if (number_channel == 1):\n","                    h, w = img_crop.shape\n","                else:\n","                    h, w, c = img_crop.shape\n","                if (h != img_size) or (w != img_size):\n","                    continue\n","\n","                out_name = out_path + str(count) + \"_\" + str(x) + \"_\" + str(y) + \".png\"\n","                # print(out_name)\n","                cv.imwrite(out_name, img_crop)\n","\n","crop10x10(in_path, out_path)                \n","images = load_images(input_image_dir)\n","mean, std = get_inception_score(images)\n","print('\\nInception mean: ', mean)\n","print('Inception std: ', std)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3neMcffzhxZP","outputId":"e9f705b0-9aab-442d-c210-8eff0642308c","executionInfo":{"status":"ok","timestamp":1639387816120,"user_tz":-540,"elapsed":3069,"user":{"displayName":"김하운","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13283057320954165001"}}},"execution_count":144,"outputs":[{"output_type":"stream","name":"stdout","text":["PACKAGES LOADED\n","./img_cgan/crop_cgan/\n","load model successfully\n","..\n","Inception mean:  4.474873539847748\n","Inception std:  0.6989032701713527\n"]}]}]}